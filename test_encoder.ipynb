{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4de60a1-6d9b-4851-accb-cb8c68bede38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo đồ thị đơn giản và lưu vào file 'simple_graph.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Tạo đồ thị đơn giản với một vài nút và cạnh\n",
    "graph = {\n",
    "    \"nodes\": [\n",
    "        {\"id\": \"1\", \"label\": \"Person\", \"properties\": {\"name\": \"Alice\", \"age\": 30}},\n",
    "        {\"id\": \"2\", \"label\": \"Person\", \"properties\": {\"name\": \"Bob\", \"age\": 25}},\n",
    "        {\"id\": \"3\", \"label\": \"Company\", \"properties\": {\"name\": \"Acme Corp\", \"industry\": \"Tech\"}}\n",
    "    ],\n",
    "    \"edges\": [\n",
    "        {\"start\": \"1\", \"end\": \"2\", \"label\": \"KNOWS\", \"properties\": {\"since\": 2010}},\n",
    "        {\"start\": \"1\", \"end\": \"3\", \"label\": \"WORKS_AT\", \"properties\": {\"role\": \"Engineer\"}},\n",
    "        {\"start\": \"2\", \"end\": \"3\", \"label\": \"WORKS_AT\", \"properties\": {\"role\": \"Designer\"}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Lưu đồ thị vào file JSON\n",
    "with open('simple_graph.json', 'w') as f:\n",
    "    json.dump(graph, f, indent=4)\n",
    "\n",
    "print(\"Đã tạo đồ thị đơn giản và lưu vào file 'simple_graph.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e526b-0b56-4798-a30c-d136cbd617d9",
   "metadata": {},
   "source": [
    "### Encoder graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee0fa8d-af40-42f0-8efd-20d37545c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đồ thị đã được mã hóa:\n",
      " G describes a graph among nodes: Person 1 (name: Alice, age: 30); Person 2 (name: Bob, age: 25); Company 3 (name: Acme Corp, industry: Tech).\n",
      "In this graph:\n",
      "Node Person 1 is connected to node Person 2 with edge KNOWS (since: 2010).\n",
      "Node Person 1 is connected to node Company 3 with edge WORKS_AT (role: Engineer).\n",
      "Node Person 2 is connected to node Company 3 with edge WORKS_AT (role: Designer).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_node_string(nodes):\n",
    "    node_strings = []\n",
    "    for node in nodes:\n",
    "        properties = \", \".join(f\"{k}: {v}\" for k, v in node[\"properties\"].items())\n",
    "        node_strings.append(f\"{node['label']} {node['id']} ({properties})\")\n",
    "    return \"; \".join(node_strings)\n",
    "\n",
    "def encode_graph(graph):\n",
    "    nodes_string = create_node_string(graph[\"nodes\"])\n",
    "    output = f\"G describes a graph among nodes: {nodes_string}.\\n\"\n",
    "    \n",
    "    if graph[\"edges\"]:\n",
    "        output += \"In this graph:\\n\"\n",
    "    \n",
    "    for edge in graph[\"edges\"]:\n",
    "        start_node = next(node for node in graph[\"nodes\"] if node[\"id\"] == edge[\"start\"])\n",
    "        end_node = next(node for node in graph[\"nodes\"] if node[\"id\"] == edge[\"end\"])\n",
    "        start_node_str = f\"{start_node['label']} {start_node['id']}\"\n",
    "        end_node_str = f\"{end_node['label']} {end_node['id']}\"\n",
    "        properties = \", \".join(f\"{k}: {v}\" for k, v in edge[\"properties\"].items())\n",
    "        \n",
    "        output += f\"Node {start_node_str} is connected to node {end_node_str} with edge {edge['label']} ({properties}).\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Mã hóa đồ thị\n",
    "encoded_graph = encode_graph(graph)\n",
    "print(\"Đồ thị đã được mã hóa:\\n\", encoded_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bf791a6-ffd3-4e18-841f-2e3dd9835fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "-------------TRUY VAN 1 -----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: No\n",
      "\n",
      "In a query, as we can notice, there are no labels specified when calling GET().\n",
      "\n",
      "Query: Find all entities with label 'Tech'\n",
      "\n",
      "\n",
      "----------TRUY VAN 2--------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: (from { Person 1 ; Company 1 } join Person 2 on (Person 1. name = Person 2. name). find_by (name = 'Alice' ) as c1)\n",
      "\n",
      "Node 1 has attribute name of : Alice\n",
      "\n",
      "As you can see, when the name attribute contains an asterisk (\"*\"), the first match found by the join is returned.\n",
      "\n",
      "Query: Find all nodes whose 'age' attribute is '30'\n",
      "\n",
      "\n",
      "------------TRUY VAN 3 ---------------\n",
      "\n",
      "\n",
      "Query answer: TRUE.\n",
      "\n",
      "What is the answer to this query?\n",
      "\n",
      "(a): TRUE\n",
      "\n",
      "(b): Not possible\n",
      "\n",
      "(c): TRUE\n",
      "\n",
      "(d) False\n",
      "\n",
      "What you actually read:\n",
      "\n",
      "The answer to this query is (a): TRUE, since they were in the same department since 2010.\n",
      "\n",
      "The second answer is also available:\n",
      "\n",
      "(a): TRUE\n",
      "\n",
      "(b): Not possible\n",
      "\n",
      "\n",
      "How to get the answer to the question:\n",
      "\n",
      "The answer to this question is (c): TRUE because both of them are in the Tech department.\n",
      "\n",
      "Query: Check the connection between node '6' and node '7'\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
    "\n",
    "# Sử dụng pipeline của Hugging Face để tạo text completion với mô hình GPT-2 XL\n",
    "generator = pipeline('text-generation', model='gpt2-xl')\n",
    "\n",
    "# Khởi tạo tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "\n",
    "# Giới hạn độ dài đầu vào\n",
    "MAX_INPUT_LENGTH = 1024\n",
    "\n",
    "# Hàm chia nhỏ chuỗi đầu vào nếu vượt quá độ dài tối đa\n",
    "def split_input(input_text, max_length=MAX_INPUT_LENGTH):\n",
    "    tokens = tokenizer.encode(input_text)\n",
    "    if len(tokens) > max_length:\n",
    "        return tokenizer.decode(tokens[:max_length])\n",
    "    return input_text\n",
    "\n",
    "# Hàm thực hiện truy vấn sử dụng mô hình lớn\n",
    "def query_huggingface(query, context):\n",
    "    input_text = f\"{context}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    input_text = split_input(input_text, MAX_INPUT_LENGTH)\n",
    "    max_length = 500  # Giới hạn độ dài đầu ra\n",
    "    input_length = len(tokenizer.encode(input_text))\n",
    "    max_new_tokens = max_length - input_length\n",
    "\n",
    "    if max_new_tokens > 0:\n",
    "        results = generator(input_text, max_length=max_length, num_return_sequences=1)\n",
    "        response = results[0]['generated_text']\n",
    "        return response.split(\"Answer:\")[1].strip()\n",
    "    else:\n",
    "        return \"Truy vấn quá dài để xử lý.\"\n",
    "\n",
    "# Ví dụ truy vấn\n",
    "print(\" \\n-------------TRUY VAN 1 -----------\\n\")\n",
    "query = \"Find all nodes with labels 'Person'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n",
    "\n",
    "# Truy vấn khác\n",
    "print(\"\\n\\n----------TRUY VAN 2--------------\\n\\n\")\n",
    "query = \"Find all nodes whose 'name' attribute is 'Alice'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n",
    "\n",
    "print(\"\\n\\n------------TRUY VAN 3 ---------------\\n\\n\")\n",
    "query = \"Check the connection between node '1' and node '2'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c46e646d-b070-46df-a80b-c06e3c30c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "-------------TRUY VAN 1 -----------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: [{\"age\":30,\"age\"\":30,\"age\"\":5}], [{\"age\":10,\"age\"\":10,\"age\"\":5}],..\n",
      "\n",
      "This query is very useful as it is a complete description. You can combine other functions to create more useful graphs.\n",
      "\n",
      "More examples\n",
      "\n",
      "Example 1: Example of an object and an additional feature, example using a multilateral graph as query:\n",
      "\n",
      "[{\"name\": \"Company\", \"industry\": \"Tech\"}, {\"name\": \"Person\", \"age\": 7}]\n",
      "\n",
      "Example 2: Example of an object and its additional nodes and edge in a multilateral graph which is not known to the object:\n",
      "\n",
      "[{\"name\":\"Computer Vision\", \"industry\": \"Computer Vision\"}, {\"name\":\"Digital Camera\", \"manufacturer\": \"Yamaha\"}, {\"name\":\"Door\", \"doorType\":2,\"state\":\"New York\"}]\n",
      "\n",
      "Example 3: Example about objects and their attributes, example connected to its graph and labeled as \"unclassifiable\":\n",
      "\n",
      "[{\"name\": \"Person\", \"age\":6}]\n",
      "\n",
      "\n",
      "Example 4a: Example (from another data source such as Google Sheet and CSV files) about objects, their attributes, edges and label as query:\n",
      "\n",
      "[{\"data\": \"company, industry, employees, location, location\", \"type\":8}]\n",
      "\n",
      "Example 4b: Example (from another data source such as CSV files):\n",
      "\n",
      "[{'age':0,\"address\":\"123 Main St E., Buffalo, NY 14206-2517\",\"name\": \"Amazon\"}]\n",
      "\n",
      "\n",
      "Example 5 (the same as [4a] from examples 2-5, but this time used by a\n",
      "\n",
      "\n",
      "----------TRUY VAN 2--------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query answer: (all of them)\n",
      "\n",
      "In this graph:\n",
      "\n",
      "Node label Person 1: KNOWS - {NAME \"Alice\",AGE 30;}\n",
      "\n",
      "Node label Person 1: WORKS_AT - {Role Engineer }\n",
      "\n",
      "Node label Person 2: WORKS_AT - {Role Designer}\n",
      "\n",
      "Node label Person 2: WORKS_AT - {Role Accountant}\n",
      "\n",
      "In this graph:\n",
      "\n",
      "Query: Determine nodes with highest 'company' attribute\n",
      "\n",
      "\n",
      "------------TRUY VAN 3 ---------------\n",
      "\n",
      "\n",
      "Query answer: the connection is in fact a single node with two label values (Person 1 and Person 2) and a single edge pointing to node 'KNOWS'. Note that there is no label 'KNOWS' but only two label values, Person 1 and Person 2. The fact that the graph has an edge only between two nodes is the key. You can even create a single edge between any two nodes in the graph.\n",
      "\n",
      "However, you cannot have edges between any two nodes in parallel; only edges that are connected in their \"top to bottom\" dimension. The following example illustrates the difference:\n",
      "\n",
      "Graph B: 2 x 2 x 2 x 2 x 2 x 2 x 2 = 4 edges\n",
      "\n",
      "Query: Check the connection between node '2' and node '3'\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ truy vấn\n",
    "print(\" \\n-------------TRUY VAN 1 -----------\\n\")\n",
    "query = \"Find all nodes with labels 'Person'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n",
    "\n",
    "# Truy vấn khác\n",
    "print(\"\\n\\n----------TRUY VAN 2--------------\\n\\n\")\n",
    "query = \"Find all nodes whose 'name' attribute is 'Alice'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n",
    "\n",
    "print(\"\\n\\n------------TRUY VAN 3 ---------------\\n\\n\")\n",
    "query = \"Check the connection between node '1' and node '2'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99df3483-95af-4569-8c8f-26a96af1d439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đồ thị đã được mã hóa:\n",
      " G describes a graph among nodes: label Person 1 with properties (name: Alice, age: 30); label Person 2 with properties (name: Bob, age: 25); label Company 3 with properties (name: Acme Corp, industry: Tech).\n",
      "In this graph:\n",
      "Node label Person 1 is connected to node label Person 2 with edge KNOWS (since: 2010).\n",
      "Node label Person 1 is connected to node label Company 3 with edge WORKS_AT (role: Engineer).\n",
      "Node label Person 2 is connected to node label Company 3 with edge WORKS_AT (role: Designer).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_node_string(nodes):\n",
    "    node_strings = []\n",
    "    for node in nodes:\n",
    "        properties = \", \".join(f\"{k}: {v}\" for k, v in node[\"properties\"].items())\n",
    "        node_strings.append(f\"label {node['label']} {node['id']} with properties ({properties})\")\n",
    "    return \"; \".join(node_strings)\n",
    "\n",
    "def encode_graph(graph):\n",
    "    nodes_string = create_node_string(graph[\"nodes\"])\n",
    "    output = f\"G describes a graph among nodes: {nodes_string}.\\n\"\n",
    "    \n",
    "    if graph[\"edges\"]:\n",
    "        output += \"In this graph:\\n\"\n",
    "    \n",
    "    for edge in graph[\"edges\"]:\n",
    "        start_node = next(node for node in graph[\"nodes\"] if node[\"id\"] == edge[\"start\"])\n",
    "        end_node = next(node for node in graph[\"nodes\"] if node[\"id\"] == edge[\"end\"])\n",
    "        start_node_str = f\"label {start_node['label']} {start_node['id']}\"\n",
    "        end_node_str = f\"label {end_node['label']} {end_node['id']}\"\n",
    "        properties = \", \".join(f\"{k}: {v}\" for k, v in edge[\"properties\"].items())\n",
    "        \n",
    "        output += f\"Node {start_node_str} is connected to node {end_node_str} with edge {edge['label']} ({properties}).\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Mã hóa đồ thị\n",
    "encoded_graph = encode_graph(graph)\n",
    "print(\"Đồ thị đã được mã hóa:\\n\", encoded_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ec6c4b4-0745-43e6-a41f-a614e57aff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, pipeline\n",
    "\n",
    "# Use Hugging Face pipeline for text completion with GPT-2 XL model\n",
    "generator = pipeline('text-generation', model='gpt2-xl')\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "\n",
    "# Maximum input length\n",
    "MAX_INPUT_LENGTH = 1024\n",
    "\n",
    "# Function to split input if it exceeds maximum length\n",
    "def split_input(input_text, max_length=MAX_INPUT_LENGTH):\n",
    "    tokens = tokenizer.encode(input_text)\n",
    "    if len(tokens) > max_length:\n",
    "        return tokenizer.decode(tokens[:max_length])\n",
    "    return input_text\n",
    "\n",
    "# Function to perform query using the large language model\n",
    "def query_huggingface(query, context):\n",
    "    input_text = f\"{context}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    input_text = split_input(input_text, MAX_INPUT_LENGTH)\n",
    "    max_length = 500  # Maximum output length\n",
    "    input_length = len(tokenizer.encode(input_text))\n",
    "    max_new_tokens = max_length - input_length\n",
    "\n",
    "    if max_new_tokens > 0:\n",
    "        # Define few-shot prompts based on query type\n",
    "        prompts = {\n",
    "            \"find_nodes_by_label\": \"List all nodes with label 'Person': Answer: Person 1 (name: Alice, age: 30); Person 2 (name: Bob, age: 25);\",\n",
    "            \"find_nodes_by_attribute\": \"Find all nodes where the 'age' attribute is 30': Answer: Person 1 (name: Alice, age: 30)\",\n",
    "            \"check_connection\": \"What is the connection between node '1' and node '2'? Answer: TRUE, relationship is KNOW\",\n",
    "        }\n",
    "\n",
    "        # Identify the appropriate prompt based on the query\n",
    "        prompt_type = None\n",
    "        if \"label\" in query.lower():\n",
    "            prompt_type = \"find_nodes_by_label\"\n",
    "        elif \"attribute\" in query.lower():\n",
    "            prompt_type = \"find_nodes_by_attribute\"\n",
    "        elif \"connection\" in query.lower():\n",
    "            prompt_type = \"check_connection\"\n",
    "\n",
    "        # Construct the final input text with prompt and context\n",
    "        if prompt_type:\n",
    "            input_text = f\"{context}\\n\\n{prompts[prompt_type].format(*query.split(' ', 1))}\\n\"\n",
    "        else:\n",
    "            input_text = f\"{context}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "\n",
    "        input_text = split_input(input_text, MAX_INPUT_LENGTH)\n",
    "\n",
    "        results = generator(input_text, max_length=max_length, num_return_sequences=1)\n",
    "        response = results[0]['generated_text']\n",
    "        return response.split(\"Answer:\")[1].strip()\n",
    "    \n",
    "    else:\n",
    "        return \"Truy vấn quá dài để xử lý.\"\n",
    "\n",
    "# Example queries\n",
    "print(\"\\n\\n-------------TRUY VAN 1 -----------\\n\\n\")\n",
    "query = \"Find all nodes with labels 'Company'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n",
    "\n",
    "print(\"\\n\\n----------TRUY VAN 2--------------\\n\\n\")\n",
    "query = \"Find all nodes whose 'name' attribute is 'Alice'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n",
    "\n",
    "print(\"\\n\\n------------TRUY VAN 3 ---------------\\n\\n\")\n",
    "query = \"Check the connection between node '2' and node '3'\"\n",
    "response = query_huggingface(query, encoded_graph)\n",
    "print(\"Query answer:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5164e97-9237-4a77-956b-7730de30de35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb51a771-c7b1-4751-a933-33a7d3e1f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (2.5.1)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.1.3)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.14.3)\n",
      "Downloading groq-0.8.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: groq\n",
      "Successfully installed groq-0.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22a1697-d8d5-473b-827c-845087184100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A nice graph query!\n",
      "\n",
      "Since we're looking for nodes with age 30, we can use a simple filter operation to find the nodes that match this condition.\n",
      "\n",
      "Let's denote the graph as `G` and the nodes as `n`. We can write the query as follows:\n",
      "\n",
      "`SELECT n AS node`\n",
      "\n",
      "`FROM G`\n",
      "\n",
      "`WHERE type(n) = \"Person\" AND age(n) = 30`\n",
      "\n",
      "This query selects all nodes `n` in graph `G` where:\n",
      "\n",
      "1. `type(n)` is \"Person\" (to filter out companies and other non-person nodes)\n",
      "2. `age(n)` is equal to 30\n",
      "\n",
      "In this case, the only node that matches this condition is \"Person 1\" (Alice), which has an age of 30.\n",
      "\n",
      "The resulting output would be a single node with properties:\n",
      "\n",
      "* Node: Person 1\n",
      "* Age: 30\n",
      "* Name: Alice\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key= \"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\",\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": encoded_graph + \"\\nQuery: Find all nodes in graph G with age is 30\" ,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d350be3-671b-47ac-8e57-e61a3ef561b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"G describes a graph among nodes: Person 1 (name: Alice, age: 30); Person 2 (name: Bob, age: 25); Company 3 (name: Acme Corp, industry: Tech).\\nIn this graph:\\nNode Person 1 is connected to node Person 2 with edge KNOWS (since: 2010).\\nNode Person 1 is connected to node Company 3 with edge WORKS_AT (role: Engineer).\\nNode Person 2 is connected to node Company 3 with edge WORKS_AT (role: Designer).\\n\\nQuery: Find all nodes in this graph with labels 'Company'\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_graph + \"\\nQuery: Find all nodes in this graph with labels 'Company'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99877e-25f9-492d-97a0-211262f4ff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
